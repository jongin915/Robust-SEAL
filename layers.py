# -*- coding: utf-8 -*-
"""layers.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jDA9YcxOIMZjUzHGfUqy6Ajq8h7FZWfS
"""

import numpy as np
import random
from tqdm import tqdm
import os, sys, pdb, math, time
import networkx as nx
import scipy.io as sio
import scipy.sparse as ssp
import multiprocessing as mp
from dgl.nn import SAGEConv, GraphConv
import torch
from torch_geometric.transforms import LineGraph
from torch_geometric.data import Data
from torch_geometric.utils import to_networkx
from torch_geometric.utils import from_networkx
from utils import *


class GGCL_F(nn.Module):
    """GGCL_F: the first layer of Robust GCN and the input is feature of nodes"""

    def __init__(self, in_feats, out_feats, dropout=0., param_var=1, is_sparse=False, bias=False, featureless=False, elu=F.elu, relu=F.relu):
        super(GGCL_F, self).__init__()
        self.dropout_rate = dropout
        self.is_sparse = is_sparse
        self.featureless = featureless
        self.out_feats = out_feats
        self.param_var = param_var

        self.weight = glorot(in_feats, out_feats)
        if bias:
            self.bias = zeros(out_feats)

        self.act_mean = elu
        self.act_var = relu

    def forward(self, adj_list, inputs, training=True):
        x = inputs
        self.adj_list = adj_list
        if training:
            if self.is_sparse:
                x = sparse_dropout(x, self.dropout_rate)
            else:
                x = F.dropout(x, self.dropout_rate)
        hidden = torch.mm(x, self.weight.cuda())
        dim = int(self.out_feats / 2)
        mean = self.act_mean(hidden[:, 0:dim])
        variance = self.act_var(hidden[:, dim:dim*2])
        self.mean = mean
        self.var = variance

        node_weight = torch.exp(-variance * self.param_var).cuda()
        mean_out = torch.mm(adj_list[0], mean * node_weight)
        var_out = torch.mm(adj_list[1], variance * node_weight * node_weight)

        outputs = torch.concat([mean_out, var_out], dim=1)
        return outputs


class GGCL_D(nn.Module):
    """GGCL: the input is distribution (mean, variance) of GGCL_F"""

    def __init__(self, in_feats, out_feats, dropout=0., param_var=1, is_sparse=False, bias=False, featureless=False, elu=F.elu, relu=F.relu):
        super(GGCL_D, self).__init__()
        self.dropout = nn.Dropout(dropout)
        self.dim = int(in_feats / 2)
        self.param_var = param_var

        self.weight_mean = glorot(self.dim, out_feats).cuda()
        self.weight_var = glorot(self.dim, out_feats).cuda()
        if bias:
            self.bias = zeros(out_feats)

        self.act_mean = elu
        self.act_var = relu

    def forward(self, adj_list, inputs, training=True):
        x = inputs
        self.adj_list = adj_list
        mean = x[:, 0:self.dim]
        variance = x[:, self.dim:self.dim*2]
        mean = self.dropout(mean)
        variance = self.dropout(variance)
        mean = self.act_mean(torch.mm(mean, self.weight_mean))
        variance = self.act_var(torch.mm(variance, self.weight_var))

        node_weight = torch.exp(-variance * self.param_var).cuda()
        mean_out = torch.mm(adj_list[0], mean * node_weight)
        var_out = torch.mm(adj_list[1], variance * node_weight * node_weight)

        sampled_v = torch.randn(var_out.shape).cuda()
        mean_out = mean_out + (torch.sqrt(var_out + 1e-8) * sampled_v)
        outputs = mean_out
        return outputs

class GNNGraph(object):
    def __init__(self, g, label, node_tags=None, node_features=None):
        '''
            g: a networkx graph
            label: an integer graph label
            node_tags: a list of integer node tags
            node_features: a numpy array of continuous node features
        '''
        self.num_nodes = len(node_tags)
        self.node_tags = node_tags
        self.label = label
        self.node_features = node_features  # numpy array (node_num * feature_dim)
        self.degs = list(dict(g.degree).values())

        if len(g.edges()) != 0:
            x, y = list(zip(*g.edges()))
            self.num_edges = len(x)        
            self.edge_pairs = np.ndarray(shape=(self.num_edges, 2), dtype=np.int32)
            self.edge_pairs[:, 0] = x
            self.edge_pairs[:, 1] = y
            self.edge_pairs = self.edge_pairs.flatten()
        else:
            self.num_edges = 0
            self.edge_pairs = np.array([])
        
        # see if there are edge features
        self.edge_features = None
        if nx.get_edge_attributes(g, 'features'):  
            # make sure edges have an attribute 'features' (1 * feature_dim numpy array)
            edge_features = nx.get_edge_attributes(g, 'features')
            assert(type(list(edge_features.values())[0]) == np.ndarray) 
            # need to rearrange edge_features using the e2n edge order
            edge_features = {(min(x, y), max(x, y)): z for (x, y), z in list(edge_features.items())}
            keys = sorted(edge_features)
            self.edge_features = []
            for edge in keys:
                self.edge_features.append(edge_features[edge])
                self.edge_features.append(edge_features[edge])  # add reversed edges
            self.edge_features = np.concatenate(self.edge_features, 0)